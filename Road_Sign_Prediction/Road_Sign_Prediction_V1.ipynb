{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary Packages\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import The necessary Packages\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import  SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change Directory\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/puneetj/Data_DL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the training Dataset\n",
    "training_set = pickle.load(open(\"training_set.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "train_X = []\n",
    "train_class = []\n",
    "for image in training_set:\n",
    "    pixel = image[\"img\"]\n",
    "    classes = image[\"class\"]\n",
    "    train_X.append(pixel)\n",
    "    train_class.append(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.38185412,  0.44826353,  0.49253647],\n",
       "        [ 0.43745882,  0.49938824,  0.54181647],\n",
       "        [ 0.44272941,  0.48225882,  0.50927059],\n",
       "        ..., \n",
       "        [ 0.41110588,  0.46315294,  0.43548235],\n",
       "        [ 0.50004706,  0.54761412,  0.46684235],\n",
       "        [ 0.4704    ,  0.51467294,  0.41229176]],\n",
       "\n",
       "       [[ 0.46486588,  0.53364706,  0.54695529],\n",
       "        [ 0.52877804,  0.60405333,  0.60766118],\n",
       "        [ 0.52665098,  0.59328627,  0.57935686],\n",
       "        ..., \n",
       "        [ 0.49430588,  0.50610196,  0.47316078],\n",
       "        [ 0.61886745,  0.62320941,  0.52109804],\n",
       "        [ 0.59939765,  0.61441882,  0.48397176]],\n",
       "\n",
       "       [[ 0.46974118,  0.52508235,  0.49741176],\n",
       "        [ 0.5347451 ,  0.61204706,  0.56727843],\n",
       "        [ 0.5225098 ,  0.6147451 ,  0.55466667],\n",
       "        ..., \n",
       "        [ 0.53270588,  0.47890196,  0.45129412],\n",
       "        [ 0.68517647,  0.62039216,  0.52131765],\n",
       "        [ 0.67661176,  0.64103529,  0.51190588]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.23849412,  0.27604706,  0.22795294],\n",
       "        [ 0.28963137,  0.33556078,  0.27789804],\n",
       "        [ 0.29976471,  0.34729412,  0.28705882],\n",
       "        ..., \n",
       "        [ 0.34619608,  0.37694118,  0.40423529],\n",
       "        [ 0.36316863,  0.38403137,  0.41069804],\n",
       "        [ 0.31294118,  0.32875294,  0.35115294]],\n",
       "\n",
       "       [[ 0.25456941,  0.29080471,  0.24943059],\n",
       "        [ 0.29930667,  0.34448314,  0.29620706],\n",
       "        [ 0.29866667,  0.34688627,  0.29716078],\n",
       "        ..., \n",
       "        [ 0.3404549 ,  0.37185882,  0.40423529],\n",
       "        [ 0.35640471,  0.37933176,  0.40964392],\n",
       "        [ 0.30595765,  0.32295529,  0.34759529]],\n",
       "\n",
       "       [[ 0.22966588,  0.26010353,  0.22966588],\n",
       "        [ 0.26313412,  0.30108235,  0.26656   ],\n",
       "        [ 0.25430588,  0.29515294,  0.26023529],\n",
       "        ..., \n",
       "        [ 0.28461176,  0.31030588,  0.34127059],\n",
       "        [ 0.30253176,  0.31610353,  0.34416941],\n",
       "        [ 0.26563765,  0.26840471,  0.29054118]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rescale the Image to 50*50\n",
    "for no,image in enumerate(train_X):\n",
    "    train_X[no] = resize(image,(50,50,3))\n",
    "    train_X[no].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# divide into test and validation set\n",
    "train = train_X[:27446]\n",
    "train_clas = train_class[:27446]\n",
    "validation = train_X[27446:]\n",
    "validation_clas = train_class[27446:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "validation = np.array(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes=max(train_class)+1\n",
    "#set shape according to dim ordering\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    train = train.reshape(train.shape[0],50, 50,3)\n",
    "    validation = validation.reshape(validation.shape[0], 50, 50,3)\n",
    "    input_shape = (50, 50,3)    \n",
    "else:\n",
    "    train = train.reshape(train.shape[0], 3, 50, 50)\n",
    "    validation = validation.reshape(validation.shape[0], 3, 50, 50)\n",
    "    input_shape = (3, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hyperparameteres\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 32\n",
    "nb_filters3 = 64\n",
    "\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters1, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='same',\n",
    "                        input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters2, kernel_size[0], kernel_size[1],border_mode='valid'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, kernel_size[0], kernel_size[1],\n",
    "                         border_mode = 'same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters3, kernel_size[0], kernel_size[1],border_mode='valid'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, kernel_size[0], kernel_size[1],\n",
    "                         border_mode = 'same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters3, kernel_size[0], kernel_size[1],border_mode='valid'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(n_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#compile model\n",
    "\n",
    "model.load_weights(\"/home/puneetj/Data_DL0.22-loss_50X50_Data_Test.h5\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "#run model\n",
    "batch_size = 128\n",
    "#using 6 epochs only, for runtime considerations\n",
    "nb_epoch = 30\n",
    "\n",
    "\n",
    "#model.fit(train, train_clas, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "     #     verbose=1, validation_data=(validation,validation_clas),callbacks=[ckpt],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes=max(train_class)+1\n",
    "train_clas = np_utils.to_categorical(train_clas, nb_classes=n_classes)\n",
    "validation_clas = np_utils.to_categorical(validation_clas, nb_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11763/11763 [==============================] - 150s   \n",
      "('Test score:', 0.22295663203348323)\n",
      "('Test accuracy:', 0.96114936665816542)\n"
     ]
    }
   ],
   "source": [
    "#Score the model \n",
    "score = model.evaluate(validation, validation_clas, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info_string = \"50X50_Data_Test\"\n",
    "ckpt_fn = \"/home/puneetj/Data_DL\" + '{val_loss:.2f}-loss_' + info_string + '.h5'\n",
    "\n",
    "ckpt = ModelCheckpoint(filepath=ckpt_fn,\n",
    "                      monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 162s   \n"
     ]
    }
   ],
   "source": [
    "validation_X = np.array(validation_X)\n",
    "#set shape according to dim ordering\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    train = train.reshape(train.shape[0],50, 50,3)\n",
    "    validation_X = validation_X.reshape(validation_X.shape[0], 50, 50,3)\n",
    "    input_shape = (50, 50,3)    \n",
    "else:\n",
    "    train = train.reshape(train.shape[0], 3, 50, 50)\n",
    "    validation_X = validation_X.reshape(validation_X.shape[0], 3, 50, 50)\n",
    "    input_shape = (3, 50, 50)\n",
    "\n",
    "pred_val = model.predict_classes(validation_X,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the test set\n",
    "import csv \n",
    "validation= pickle.load(open(\"testing_set.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_X = []\n",
    "for image in validation:\n",
    "    pixel = image[\"img\"]\n",
    "    validation_X.append(pixel)\n",
    "for no,image in enumerate(validation_X):\n",
    "    validation_X[no] = resize(image,(50,50,3))\n",
    "    validation_X[no].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the submission CSV\n",
    "csv_out = open(\"submission_.23.csv\",'wb')\n",
    "mywriter = csv.writer(csv_out)\n",
    "mywriter.writerow(pred_val.tolist())\n",
    "csv_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
